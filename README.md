# ğŸ“Š Results Summary

### ğŸ”¹ Logistic Regression
- **Val Accuracy:** <span style="color:orange; font-weight:bold;">0.639</span>  
- **Test Accuracy:** <span style="color:red; font-weight:bold;">0.613</span>  
- **F1:** ğŸŸ¡ decent, but accuracy is low â†’ **underfitting**

---

### ğŸŒ² Random Forest
- **Val Accuracy:** <span style="color:orange; font-weight:bold;">0.656</span>  
- **Test Accuracy:** <span style="color:red; font-weight:bold;">0.613</span>  
- **F1:** ğŸŸ¡ similar to Logistic â†’ also underperforming on test

---

### ğŸš€ XGBoost
- **Val Accuracy:** <span style="color:green; font-weight:bold;">0.705 âœ…</span> (best on validation)  
- **Test Accuracy:** <span style="color:red; font-weight:bold;">0.613</span> (still not generalizing well)  
- **F1:** ğŸŸ¢ higher than others, but not translating to test accuracy  

---

# ğŸ” Observations
- Models are **failing to generalize** â†’ all three are stuck at  
  <span style="color:red; font-weight:bold;">~61% Test Accuracy</span>  
  despite XGBoost showing good validation performance.  

This suggests:
1. âš ï¸ **Overfitting** (XGBoost especially).  
2. ğŸ”„ **Data leakage / distribution shift** between Train/Val/Test.  
3. ğŸ­ **PCA may have removed important signal** from the data.  

---

# âœ… Next Steps

1. **ğŸš« Try without PCA**  
   - PCA can reduce predictive power if target-related variance is lost.  
   - Re-train models **without dimensionality reduction**.  

2. **ğŸ¯ Hyperparameter Tuning**  
   - Use **GridSearchCV / RandomizedSearchCV** for XGBoost & Random Forest.  
   - Key params:  
     - `n_estimators`, `max_depth`, `learning_rate`,  
       `min_child_weight`, `subsample`.  

3. **ğŸ” Cross-Validation (k-fold)**  
   - Replace single validation split with **5-fold CV**  
     for more reliable results.  

4. **ğŸ§ Check Data Leakage / Shift**  
   - Compare **feature distributions** in Train vs Test.  
   - If distributions differ â†’ preprocessing split issue.  

5. **ğŸ†• Try Other Models**  
   - **LightGBM, CatBoost** â†’ strong with categorical data.  
   - Try **Ensemble (stacking XGBoost + Logistic)**.  

---

# Loan-Approval-Prediction-
